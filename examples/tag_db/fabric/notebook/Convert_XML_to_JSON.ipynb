{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de89045",
   "metadata": {},
   "source": [
    "# Convert TAG DB XML to JSON\n",
    "\n",
    "This notebook converts TAG DB XML files to JSON format for processing by the Purview_TAG_DB_Scan notebook.\n",
    "\n",
    "## Prerequisites\n",
    "- XML files uploaded to `tag-db-xml/` folder in your storage account\n",
    "- Storage account configured with proper access\n",
    "\n",
    "## Workflow\n",
    "1. Reads XML files from `tag-db-xml/` folder\n",
    "2. Converts each XML file to JSON using xmltodict\n",
    "3. Saves JSON files to `tag-db-json/` folder\n",
    "4. Optionally moves processed XML files to archive folder\n",
    "\n",
    "## Configuration\n",
    "Update the configuration cell below with your infrastructure settings before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5969e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage Configuration\n",
    "blob_container_name = \"pccsa\"\n",
    "blob_account_name = \"pccsast6nvsfni5vtcj6\"\n",
    "blob_xml_path = \"tag-db-xml\"  # Input: XML files\n",
    "blob_json_path = \"tag-db-json\"  # Output: JSON files\n",
    "blob_xml_archive = \"tag-db-xml-processed\"  # Optional: Archive processed XML files\n",
    "\n",
    "# Processing Options\n",
    "archive_processed_xml = False  # Set to True to move processed XML files to archive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xmltodict\n",
    "from notebookutils import mssparkutils\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ADLS paths\n",
    "adls_xml_path = f'abfss://{blob_container_name}@{blob_account_name}.dfs.core.windows.net/{blob_xml_path}'\n",
    "adls_json_path = f'abfss://{blob_container_name}@{blob_account_name}.dfs.core.windows.net/{blob_json_path}'\n",
    "adls_xml_archive = f'abfss://{blob_container_name}@{blob_account_name}.dfs.core.windows.net/{blob_xml_archive}'\n",
    "\n",
    "print(f\"XML Source: {adls_xml_path}\")\n",
    "print(f\"JSON Destination: {adls_json_path}\")\n",
    "print(f\"XML Archive: {adls_xml_archive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f37316",
   "metadata": {},
   "source": [
    "## Convert XML Files to JSON\n",
    "\n",
    "This cell processes all XML files in the source folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "try:\n",
    "    # Get list of XML files\n",
    "    print(f\"\\nüîç Scanning for XML files in: {adls_xml_path}\")\n",
    "    files = mssparkutils.fs.ls(adls_xml_path)\n",
    "    \n",
    "    xml_files = [f for f in files if f.name.lower().endswith('.xml') and f.size > 0]\n",
    "    \n",
    "    if len(xml_files) == 0:\n",
    "        print(\"‚ö†Ô∏è  No XML files found to process\")\n",
    "    else:\n",
    "        print(f\"\\nüìÅ Found {len(xml_files)} XML file(s) to process\\n\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        for file in xml_files:\n",
    "            try:\n",
    "                print(f\"\\nüìÑ Processing: {file.name}\")\n",
    "                print(f\"   Size: {file.size:,} bytes\")\n",
    "                \n",
    "                # Read XML file (read entire file, adjust if files are very large)\n",
    "                xml_content = mssparkutils.fs.head(file.path, file.size)\n",
    "                \n",
    "                # Convert XML to dictionary\n",
    "                print(\"   üîÑ Converting XML to JSON...\")\n",
    "                data_dict = xmltodict.parse(xml_content)\n",
    "                \n",
    "                # Convert to JSON\n",
    "                json_output = json.dumps(data_dict, indent=2)\n",
    "                \n",
    "                # Generate output filename (replace .xml with .json)\n",
    "                json_filename = file.name.replace('.xml', '.json').replace('.XML', '.json')\n",
    "                json_file_path = f\"{adls_json_path}/{json_filename}\"\n",
    "                \n",
    "                # Save JSON file\n",
    "                print(f\"   üíæ Saving JSON: {json_filename}\")\n",
    "                mssparkutils.fs.put(json_file_path, json_output, overwrite=True)\n",
    "                \n",
    "                # Archive processed XML file if enabled\n",
    "                if archive_processed_xml:\n",
    "                    archive_path = f\"{adls_xml_archive}/{file.name}\"\n",
    "                    print(f\"   üì¶ Archiving XML to: {blob_xml_archive}/{file.name}\")\n",
    "                    try:\n",
    "                        # Delete existing file in archive if it exists\n",
    "                        mssparkutils.fs.rm(archive_path, recurse=False)\n",
    "                    except:\n",
    "                        pass\n",
    "                    mssparkutils.fs.mv(file.path, archive_path)\n",
    "                \n",
    "                print(f\"   ‚úÖ Success!\")\n",
    "                processed_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error processing {file.name}:\")\n",
    "                print(f\"      {str(e)}\")\n",
    "                failed_count += 1\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìä Conversion Summary\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"   ‚úÖ Successfully converted: {processed_count}\")\n",
    "        print(f\"   ‚ùå Failed: {failed_count}\")\n",
    "        print(f\"   üìÅ Total files: {len(xml_files)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if processed_count > 0:\n",
    "            print(f\"\\n‚ú® JSON files are ready in: {blob_json_path}/\")\n",
    "            print(f\"\\n‚ñ∂Ô∏è  Next step: Run the 'Purview_TAG_DB_Scan' notebook\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Fatal error during conversion:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    traceback_lines = traceback.format_exc()\n",
    "    print(traceback_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76ebc6",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Check the generated JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List JSON files\n",
    "try:\n",
    "    json_files = mssparkutils.fs.ls(adls_json_path)\n",
    "    print(f\"\\nüìã JSON files in {blob_json_path}:\")\n",
    "    print(\"=\" * 60)\n",
    "    for f in json_files:\n",
    "        if f.name.lower().endswith('.json'):\n",
    "            print(f\"   üìÑ {f.name} ({f.size:,} bytes)\")\n",
    "    print(\"=\" * 60)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  No files found or error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2ee46",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After successful conversion:\n",
    "\n",
    "1. **Verify JSON files** are in `tag-db-json/` folder\n",
    "2. **Run the Purview_TAG_DB_Scan notebook** with this configuration:\n",
    "   ```python\n",
    "   blob_relative_path = \"tag-db-json\"  # Read from JSON folder\n",
    "   ```\n",
    "3. The scanner will process the JSON files and generate Purview entity definitions\n",
    "\n",
    "**Folder Structure:**\n",
    "- `tag-db-xml/` ‚Üí Input XML files (source)\n",
    "- `tag-db-json/` ‚Üí Converted JSON files (intermediate)\n",
    "- `tag-db-purview-json/` ‚Üí Purview entity JSON (output from scanner)\n",
    "- `tag-db-processed/` ‚Üí Archive for processed JSON files (from scanner)\n",
    "- `tag-db-xml-processed/` ‚Üí Archive for processed XML files (optional)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
